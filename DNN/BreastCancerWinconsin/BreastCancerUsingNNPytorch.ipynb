{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BreastCancerUsingNNPytorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN2VK8c/Hn7fTsVh4hrs/qW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zfIBjsUkyZKv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592993362648,"user_tz":-330,"elapsed":893,"user":{"displayName":"Deep Patel","photoUrl":"","userId":"04712700746129152962"}}},"source":["import torch\n","import numpy as np\n","import pandas as pd\n","from sklearn import datasets\n","import torch.nn.functional as F\n","import torch.nn as nn \n","from torch import optim\n","from sklearn.model_selection import train_test_split\n","import time\n","import copy"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"AiFTW4isymdK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592993129943,"user_tz":-330,"elapsed":4856,"user":{"displayName":"Deep Patel","photoUrl":"","userId":"04712700746129152962"}},"outputId":"54d1f6d0-054a-4fb9-b3fe-f6aa5a9e6451"},"source":["breast_cancer=datasets.load_breast_cancer()\n","X=breast_cancer.data\n","Y=breast_cancer.target\n","print(X.shape,Y.shape)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["(569, 30) (569,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TRW61CSd0Hv5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":146},"executionInfo":{"status":"ok","timestamp":1592993129947,"user_tz":-330,"elapsed":4683,"user":{"displayName":"Deep Patel","photoUrl":"","userId":"04712700746129152962"}},"outputId":"322cffa7-03d4-4f07-92d0-e7e72fe56b48"},"source":["from sklearn import preprocessing\n","mm_scaler = preprocessing.MinMaxScaler()\n","X = mm_scaler.fit_transform(X)\n","print(X)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[[0.52103744 0.0226581  0.54598853 ... 0.91202749 0.59846245 0.41886396]\n"," [0.64314449 0.27257355 0.61578329 ... 0.63917526 0.23358959 0.22287813]\n"," [0.60149557 0.3902604  0.59574321 ... 0.83505155 0.40370589 0.21343303]\n"," ...\n"," [0.45525108 0.62123774 0.44578813 ... 0.48728522 0.12872068 0.1519087 ]\n"," [0.64456434 0.66351031 0.66553797 ... 0.91065292 0.49714173 0.45231536]\n"," [0.03686876 0.50152181 0.02853984 ... 0.         0.25744136 0.10068215]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hmce3-um0JX2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592993129948,"user_tz":-330,"elapsed":1795,"user":{"displayName":"Deep Patel","photoUrl":"","userId":"04712700746129152962"}},"outputId":"4e7ec800-27e0-47cd-8a19-cd04a8e30282"},"source":["#splitting data into  80% train and 20% test\n","X_train,X_test,Y_train,Y_test=train_test_split(X,Y,stratify=Y,random_state=4,test_size=0.20)\n","print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["(455, 30) (114, 30) (455,) (114,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h2cMMfp01WYC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":92},"executionInfo":{"status":"ok","timestamp":1592993960437,"user_tz":-330,"elapsed":944,"user":{"displayName":"Deep Patel","photoUrl":"","userId":"04712700746129152962"}},"outputId":"9a2ce989-7c3a-4462-ceca-ba000950d562"},"source":["#covert all data into tensors\n","X_train,X_test,Y_train,Y_test=map(torch.tensor ,(X_train,X_test,Y_train,Y_test))\n","print(X_train.dtype, X_test.dtype, Y_train.dtype, Y_test.dtype)\n","#print(Y_train)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["torch.float32 torch.float32 torch.int64 torch.int64\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"r0FszCKc1cSe","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592993132899,"user_tz":-330,"elapsed":860,"user":{"displayName":"Deep Patel","photoUrl":"","userId":"04712700746129152962"}}},"source":["#convert all tensors to float to avoid in training\n","X_train=X_train.float()\n","X_test=X_test.float()\n","Y_train=Y_train.long()\n","Y_test=Y_test.long()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"cV7z3zvq1ffT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592993134082,"user_tz":-330,"elapsed":634,"user":{"displayName":"Deep Patel","photoUrl":"","userId":"04712700746129152962"}}},"source":["#constructing class to built neural network\n","class Classfication(nn.Module):\n","  def __init__(self):\n","     super().__init__()\n","     torch.manual_seed(0)\n","     self.net=nn.Sequential(\n","         nn.Linear(30,50),\n","         nn.ReLU(),\n","         nn.Linear(50,100),\n","         nn.ReLU(),\n","         nn.Linear(100,50),\n","         nn.ReLU(),\n","         nn.Linear(50,2),\n","         nn.Softmax()\n","     )\n","  def forward(self,x):\n","    return self.net(x)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"tPp6Ts0T1jkv","colab_type":"code","colab":{}},"source":[" def accuracy(X,y):\n","    y_hat=model(X)\n","    y_np=y_hat.detach().cpu().numpy()\n","    y_model=np.argmax(y_np,axis=1)\n","    y_test=y.detach().cpu().numpy()\n","    count=0\n","    for y_pred,y_true in zip(y_model,y_test):\n","      if(y_pred==y_true):\n","          count=count + 1\n","    accuracy=(count/y_model.shape[0])*100\n","    #print(\"accuracy:\",accuracy)\n","    return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SYs3CWPZ1o66","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592993678303,"user_tz":-330,"elapsed":979,"user":{"displayName":"Deep Patel","photoUrl":"","userId":"04712700746129152962"}}},"source":["def fit_gpu(X_train,X_test,Y_test,Y_train,model,opt,loss_fn,epochs=100):\n","        #callback=StopatLossValue()\n","        time0=time.time()\n","        trainloss=[]\n","        valloss=[]\n","        trainacclist=[]\n","        valacclist=[]\n","        min_valloss=10000000.0000000\n","        min_trainloss=10000000.0000000\n","        max_valacc=0.0\n","        max_trainacc=0.0\n","        for epoch in range(epochs):\n","            runningtrain_loss=0\n","            runningval_loss=0\n","            vallen=114\n","            trainlen=455\n","            #init_fn()\n","            inputs, labels = X_train,Y_train\n","            inputs=inputs.to(device)\n","            labels=labels.to(device)\n","\n","                #forward pass\n","            loss = loss_fn(model(inputs), labels)\n","\n","                #backward and optimize\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","            trainacc=accuracy(inputs,labels)   \n","                #loss_arr.append(loss.item())\n","            runningtrain_loss += loss.item()\n","            #init_fn()\n","            inputs, labels = X_test,Y_test\n","            inputs=inputs.to(device)\n","            labels=labels.to(device)\n","\n","                #forward pass\n","            loss = loss_fn(model(inputs), labels)\n","                #valloss_arr.append(loss.item())\n","            valacc=accuracy(inputs,labels)\n","            runningval_loss += loss.item()\n","            avgval_loss=runningval_loss/vallen\n","            avgtrain_loss=runningtrain_loss/trainlen\n","            if (avgval_loss<min_valloss):\n","                min_valloss=avgval_loss    \n","                vallossmodel=copy.deepcopy(model.state_dict())\n","            if (avgtrain_loss<min_trainloss):\n","                min_trainloss=avgtrain_loss\n","                trainlossmodel=copy.deepcopy(model.state_dict())\n","            \n","            \n","            trainacclist.append(trainacc)\n","            valacclist.append(valacc)\n","            if (trainacc>max_trainacc):\n","                max_trainacc=trainacc\n","                trainaccmodel=copy.deepcopy(model.state_dict())\n","            if (valacc>max_valacc):\n","                max_trainacc=valacc\n","                valaccmodel=copy.deepcopy(model.state_dict())      \n","            print(\"Minimum training Loss :\",min_trainloss,\"| Minimum validation Loss :\",min_valloss) \n","            print(\"Epoch {} - Training loss: {}\".format(epoch,avgtrain_loss ),\"| validation loss: {}\".format(avgval_loss))    \n","            print('Epoch: %d/%d, Train acc: %0.2f' % (epoch, epochs-1,trainacc ),'| val acc: %0.2f' % (valacc))\n","            print('------------------------------------------------------------------------------------------')\n","            trainloss.append(avgtrain_loss)       \n","            valloss.append(avgval_loss)\n","            #vis.line(Y=avgtrain_loss, opts=dict(showlegend=True))\n","        print(\"Training Time(in minutes) =\",(time.time()-time0)/60)    \n","        return vallossmodel,trainlossmodel,valaccmodel,trainaccmodel,trainloss,valloss,trainacclist,valacclist"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"nD-qfWhay66b","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592993679712,"user_tz":-330,"elapsed":660,"user":{"displayName":"Deep Patel","photoUrl":"","userId":"04712700746129152962"}}},"source":["device=torch.device(\"cuda\")"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"myFMUXmV1ril","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592993885140,"user_tz":-330,"elapsed":1978,"user":{"displayName":"Deep Patel","photoUrl":"","userId":"04712700746129152962"}},"outputId":"2d30be35-7611-4f8f-ecb4-33e30f06f456"},"source":["model=Classfication()\n","model=model.to(device)\n","loss_fn=F.cross_entropy\n","opt=optim.Adam(model.parameters(),lr=0.01)\n","vallossmodel,trainlossmodel,valaccmodel,trainaccmodel,trainloss,valloss,trainacclist,valacclist=fit_gpu(X_train,X_test,Y_test,Y_train,model,opt,loss_fn)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n"],"name":"stderr"},{"output_type":"stream","text":["Minimum training Loss : 0.001517535041976761 | Minimum validation Loss : 0.005914659353724697\n","Epoch 0 - Training loss: 0.001517535041976761 | validation loss: 0.005914659353724697\n","Epoch: 0/99, Train acc: 62.64 | val acc: 63.16\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0014835108767498981 | Minimum validation Loss : 0.005748351937846134\n","Epoch 1 - Training loss: 0.0014835108767498981 | validation loss: 0.005748351937846134\n","Epoch: 1/99, Train acc: 62.64 | val acc: 63.16\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0014440784087547888 | Minimum validation Loss : 0.005505496995490894\n","Epoch 2 - Training loss: 0.0014440784087547888 | validation loss: 0.005505496995490894\n","Epoch: 2/99, Train acc: 63.08 | val acc: 63.16\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0013868060740795764 | Minimum validation Loss : 0.005151671798605668\n","Epoch 3 - Training loss: 0.0013868060740795764 | validation loss: 0.005151671798605668\n","Epoch: 3/99, Train acc: 72.31 | val acc: 74.56\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0013030259163825067 | Minimum validation Loss : 0.0046955707826112445\n","Epoch 4 - Training loss: 0.0013030259163825067 | validation loss: 0.0046955707826112445\n","Epoch: 4/99, Train acc: 87.03 | val acc: 88.60\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0011973297202980124 | Minimum validation Loss : 0.004222026519608079\n","Epoch 5 - Training loss: 0.0011973297202980124 | validation loss: 0.004222026519608079\n","Epoch: 5/99, Train acc: 89.45 | val acc: 94.74\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0010895206378056452 | Minimum validation Loss : 0.003792629691592434\n","Epoch 6 - Training loss: 0.0010895206378056452 | validation loss: 0.003792629691592434\n","Epoch: 6/99, Train acc: 91.65 | val acc: 96.49\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0009921893968686953 | Minimum validation Loss : 0.0034942579896826494\n","Epoch 7 - Training loss: 0.0009921893968686953 | validation loss: 0.0034942579896826494\n","Epoch: 7/99, Train acc: 94.29 | val acc: 95.61\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0009136874597151201 | Minimum validation Loss : 0.0032154792233517297\n","Epoch 8 - Training loss: 0.0009136874597151201 | validation loss: 0.0032154792233517297\n","Epoch: 8/99, Train acc: 93.63 | val acc: 99.12\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000860369663972121 | Minimum validation Loss : 0.0031517229059286286\n","Epoch 9 - Training loss: 0.000860369663972121 | validation loss: 0.0031517229059286286\n","Epoch: 9/99, Train acc: 93.41 | val acc: 95.61\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000831774957887419 | Minimum validation Loss : 0.0030078108896288954\n","Epoch 10 - Training loss: 0.000831774957887419 | validation loss: 0.0030078108896288954\n","Epoch: 10/99, Train acc: 94.29 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0008156731888488099 | Minimum validation Loss : 0.0030078108896288954\n","Epoch 11 - Training loss: 0.0008156731888488099 | validation loss: 0.0030840352961891576\n","Epoch: 11/99, Train acc: 94.07 | val acc: 95.61\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0008085210244734209 | Minimum validation Loss : 0.0029413585077252306\n","Epoch 12 - Training loss: 0.0008085210244734209 | validation loss: 0.0029413585077252306\n","Epoch: 12/99, Train acc: 94.51 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0008025147102691315 | Minimum validation Loss : 0.0029413585077252306\n","Epoch 13 - Training loss: 0.0008025147102691315 | validation loss: 0.0030046772015722176\n","Epoch: 13/99, Train acc: 94.73 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007900803953736693 | Minimum validation Loss : 0.0029202155899583247\n","Epoch 14 - Training loss: 0.0007900803953736693 | validation loss: 0.0029202155899583247\n","Epoch: 14/99, Train acc: 96.04 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007747302998553266 | Minimum validation Loss : 0.002912373657812152\n","Epoch 15 - Training loss: 0.0007747302998553266 | validation loss: 0.002912373657812152\n","Epoch: 15/99, Train acc: 96.48 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007678392169239757 | Minimum validation Loss : 0.002912373657812152\n","Epoch 16 - Training loss: 0.0007678392169239757 | validation loss: 0.00295199453830719\n","Epoch: 16/99, Train acc: 96.26 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007678392169239757 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 17 - Training loss: 0.0007690988399170258 | validation loss: 0.0029088237829375686\n","Epoch: 17/99, Train acc: 96.04 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007678392169239757 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 18 - Training loss: 0.0007733758989271227 | validation loss: 0.0029258223479254205\n","Epoch: 18/99, Train acc: 97.58 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007487696605724293 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 19 - Training loss: 0.0007487696605724293 | validation loss: 0.00291887945250461\n","Epoch: 19/99, Train acc: 98.02 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007399247242854192 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 20 - Training loss: 0.0007399247242854192 | validation loss: 0.0029094198293853225\n","Epoch: 20/99, Train acc: 97.58 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007399247242854192 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 21 - Training loss: 0.0007430615005912362 | validation loss: 0.0029260874317403427\n","Epoch: 21/99, Train acc: 98.02 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007363067223475529 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 22 - Training loss: 0.0007363067223475529 | validation loss: 0.002926416825829891\n","Epoch: 22/99, Train acc: 98.46 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007312259831271328 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 23 - Training loss: 0.0007312259831271328 | validation loss: 0.00291881801789267\n","Epoch: 23/99, Train acc: 98.02 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007312259831271328 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 24 - Training loss: 0.0007341270918374533 | validation loss: 0.002941544118680452\n","Epoch: 24/99, Train acc: 98.02 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007312259831271328 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 25 - Training loss: 0.0007339264010335063 | validation loss: 0.002939673892238684\n","Epoch: 25/99, Train acc: 98.46 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007268398017673702 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 26 - Training loss: 0.0007268398017673702 | validation loss: 0.002929420324794033\n","Epoch: 26/99, Train acc: 98.02 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007268398017673702 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 27 - Training loss: 0.0007293817106184069 | validation loss: 0.002952019634999727\n","Epoch: 27/99, Train acc: 98.24 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007268398017673702 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 28 - Training loss: 0.0007280795128790887 | validation loss: 0.0029524039281042\n","Epoch: 28/99, Train acc: 98.68 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000725331214758066 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 29 - Training loss: 0.000725331214758066 | validation loss: 0.0029272421410209254\n","Epoch: 29/99, Train acc: 98.24 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000725331214758066 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 30 - Training loss: 0.0007288981925000201 | validation loss: 0.0029624684860831813\n","Epoch: 30/99, Train acc: 98.24 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000725331214758066 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 31 - Training loss: 0.0007265181986840217 | validation loss: 0.002962197650942886\n","Epoch: 31/99, Train acc: 98.24 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000725331214758066 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 32 - Training loss: 0.0007254155782552866 | validation loss: 0.0029214947370060705\n","Epoch: 32/99, Train acc: 98.46 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000725331214758066 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 33 - Training loss: 0.000728255182832152 | validation loss: 0.0029671254910920795\n","Epoch: 33/99, Train acc: 98.24 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007251824651445661 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 34 - Training loss: 0.0007251824651445661 | validation loss: 0.002967048632471185\n","Epoch: 34/99, Train acc: 98.24 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007245272725493043 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 35 - Training loss: 0.0007245272725493043 | validation loss: 0.0029182366111822297\n","Epoch: 35/99, Train acc: 98.46 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007245272725493043 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 36 - Training loss: 0.0007259607315063477 | validation loss: 0.0029552199861459564\n","Epoch: 36/99, Train acc: 98.68 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000722803322823493 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 37 - Training loss: 0.000722803322823493 | validation loss: 0.002965517472802547\n","Epoch: 37/99, Train acc: 98.24 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000722803322823493 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 38 - Training loss: 0.0007235941651103261 | validation loss: 0.0029233686233821666\n","Epoch: 38/99, Train acc: 98.46 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000722803322823493 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 39 - Training loss: 0.0007229370730263846 | validation loss: 0.0029295837147194042\n","Epoch: 39/99, Train acc: 98.46 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007222099618597345 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 40 - Training loss: 0.0007222099618597345 | validation loss: 0.002960607148053353\n","Epoch: 40/99, Train acc: 98.68 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007222099618597345 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 41 - Training loss: 0.0007226493987408313 | validation loss: 0.002944263449886389\n","Epoch: 41/99, Train acc: 98.46 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007215427173362984 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 42 - Training loss: 0.0007215427173362984 | validation loss: 0.002920250359334444\n","Epoch: 42/99, Train acc: 98.68 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007215427173362984 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 43 - Training loss: 0.0007221907049744994 | validation loss: 0.002942764445355064\n","Epoch: 43/99, Train acc: 98.46 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007211594791202754 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 44 - Training loss: 0.0007211594791202754 | validation loss: 0.002949741064456471\n","Epoch: 44/99, Train acc: 98.68 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007211594791202754 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 45 - Training loss: 0.0007212922468290224 | validation loss: 0.0029207316406986168\n","Epoch: 45/99, Train acc: 98.68 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007209213880392221 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 46 - Training loss: 0.0007209213880392221 | validation loss: 0.0029306681009761072\n","Epoch: 46/99, Train acc: 98.68 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007200601991716322 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 47 - Training loss: 0.0007200601991716322 | validation loss: 0.0029508021839878013\n","Epoch: 47/99, Train acc: 98.68 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007200601991716322 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 48 - Training loss: 0.0007203527204282991 | validation loss: 0.00291997142005385\n","Epoch: 48/99, Train acc: 98.68 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007199907695854104 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 49 - Training loss: 0.0007199907695854104 | validation loss: 0.002938543495378996\n","Epoch: 49/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007191392746600476 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 50 - Training loss: 0.0007191392746600476 | validation loss: 0.002940777623862551\n","Epoch: 50/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007189816170996362 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 51 - Training loss: 0.0007189816170996362 | validation loss: 0.002919047286635951\n","Epoch: 51/99, Train acc: 98.68 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007189816170996362 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 52 - Training loss: 0.0007194704406864041 | validation loss: 0.0029623294085787052\n","Epoch: 52/99, Train acc: 98.46 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007189816170996362 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 53 - Training loss: 0.0007201488856430892 | validation loss: 0.002917041119776274\n","Epoch: 53/99, Train acc: 98.68 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007189816170996362 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 54 - Training loss: 0.0007194726021735223 | validation loss: 0.0029520347975848012\n","Epoch: 54/99, Train acc: 98.68 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007189816170996362 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 55 - Training loss: 0.0007189912455422537 | validation loss: 0.0029237756603642515\n","Epoch: 55/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007183242630172562 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 56 - Training loss: 0.0007183242630172562 | validation loss: 0.0029356547614984344\n","Epoch: 56/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007179541902227716 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 57 - Training loss: 0.0007179541902227716 | validation loss: 0.002932129983316388\n","Epoch: 57/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007177375175140716 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 58 - Training loss: 0.0007177375175140716 | validation loss: 0.002925650853859751\n","Epoch: 58/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007176364516163921 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 59 - Training loss: 0.0007176364516163921 | validation loss: 0.0029410160424416525\n","Epoch: 59/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007176364516163921 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 60 - Training loss: 0.0007176585904844515 | validation loss: 0.0029179686517046208\n","Epoch: 60/99, Train acc: 98.68 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007176364516163921 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 61 - Training loss: 0.0007177990216475266 | validation loss: 0.0029490997916773744\n","Epoch: 61/99, Train acc: 98.68 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007176364516163921 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 62 - Training loss: 0.0007179228814093621 | validation loss: 0.0029144488405763056\n","Epoch: 62/99, Train acc: 98.68 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007176364516163921 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 63 - Training loss: 0.0007179879880213476 | validation loss: 0.0029464745730684513\n","Epoch: 63/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007175196003127884 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 64 - Training loss: 0.0007175196003127884 | validation loss: 0.002919546867671766\n","Epoch: 64/99, Train acc: 98.68 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007171601384550661 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 65 - Training loss: 0.0007171601384550661 | validation loss: 0.002936864892641703\n","Epoch: 65/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007167765072413853 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 66 - Training loss: 0.0007167765072413853 | validation loss: 0.0029295133916955244\n","Epoch: 66/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007165714279635922 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 67 - Training loss: 0.0007165714279635922 | validation loss: 0.0029283097961492707\n","Epoch: 67/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000716484247983157 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 68 - Training loss: 0.000716484247983157 | validation loss: 0.0029389047831819767\n","Epoch: 68/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000716484247983157 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 69 - Training loss: 0.000716491583939437 | validation loss: 0.0029210111028269716\n","Epoch: 69/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000716484247983157 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 70 - Training loss: 0.0007166283471243722 | validation loss: 0.002948923330557974\n","Epoch: 70/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000716484247983157 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 71 - Training loss: 0.00071684357884166 | validation loss: 0.002914730132671825\n","Epoch: 71/99, Train acc: 98.68 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000716484247983157 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 72 - Training loss: 0.000717243322959313 | validation loss: 0.002957855923133984\n","Epoch: 72/99, Train acc: 98.68 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000716484247983157 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 73 - Training loss: 0.0007175009984236497 | validation loss: 0.0029130774108987105\n","Epoch: 73/99, Train acc: 98.68 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000716484247983157 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 74 - Training loss: 0.0007174047794970837 | validation loss: 0.002955446640650431\n","Epoch: 74/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000716484247983157 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 75 - Training loss: 0.0007170247507619333 | validation loss: 0.0029165750009971752\n","Epoch: 75/99, Train acc: 98.68 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000716484247983157 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 76 - Training loss: 0.000716586165375762 | validation loss: 0.002947885739175897\n","Epoch: 76/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007161874037522536 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 77 - Training loss: 0.0007161874037522536 | validation loss: 0.0029215159123403985\n","Epoch: 77/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007159368022457583 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 78 - Training loss: 0.0007159368022457583 | validation loss: 0.0029430551487102845\n","Epoch: 78/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007157438403957493 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 79 - Training loss: 0.0007157438403957493 | validation loss: 0.0029246974409672254\n","Epoch: 79/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007156187361413306 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 80 - Training loss: 0.0007156187361413306 | validation loss: 0.002941355632062544\n","Epoch: 80/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007155177357432606 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 81 - Training loss: 0.0007155177357432606 | validation loss: 0.0029257828729194507\n","Epoch: 81/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007154424111921709 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 82 - Training loss: 0.0007154424111921709 | validation loss: 0.0029416024162058243\n","Epoch: 82/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007153745535965804 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 83 - Training loss: 0.0007153745535965804 | validation loss: 0.0029255841907701993\n","Epoch: 83/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007153184859307257 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 84 - Training loss: 0.0007153184859307257 | validation loss: 0.002942613342352081\n","Epoch: 84/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007152622217660422 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 85 - Training loss: 0.0007152622217660422 | validation loss: 0.0029250571602269224\n","Epoch: 85/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007152069400955032 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 86 - Training loss: 0.0007152069400955032 | validation loss: 0.00294294770349536\n","Epoch: 86/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007151415059854696 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 87 - Training loss: 0.0007151415059854696 | validation loss: 0.0029254001483582613\n","Epoch: 87/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000715060286469512 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 88 - Training loss: 0.000715060286469512 | validation loss: 0.002941168191140158\n","Epoch: 88/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007149612510597312 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 89 - Training loss: 0.0007149612510597312 | validation loss: 0.0029277040770179347\n","Epoch: 89/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007148521942096752 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 90 - Training loss: 0.0007148521942096752 | validation loss: 0.002936619938465587\n","Epoch: 90/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007147474603338556 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 91 - Training loss: 0.0007147474603338556 | validation loss: 0.002932155864280567\n","Epoch: 91/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007146634243346833 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 92 - Training loss: 0.0007146634243346833 | validation loss: 0.0029309088723701343\n","Epoch: 92/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007146048021840526 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 93 - Training loss: 0.0007146048021840526 | validation loss: 0.00293637027865962\n","Epoch: 93/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007145560704744779 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 94 - Training loss: 0.0007145560704744779 | validation loss: 0.0029280781745910645\n","Epoch: 94/99, Train acc: 98.90 | val acc: 98.25\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007144897193699092 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 95 - Training loss: 0.0007144897193699092 | validation loss: 0.0029362913286476804\n","Epoch: 95/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.000714380335021805 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 96 - Training loss: 0.000714380335021805 | validation loss: 0.002931229639471623\n","Epoch: 96/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007142188784840343 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 97 - Training loss: 0.0007142188784840343 | validation loss: 0.0029330789520029435\n","Epoch: 97/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007139405051430503 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 98 - Training loss: 0.0007139405051430503 | validation loss: 0.0029405436494894196\n","Epoch: 98/99, Train acc: 98.90 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Minimum training Loss : 0.0007131824781606486 | Minimum validation Loss : 0.0029088237829375686\n","Epoch 99 - Training loss: 0.0007131824781606486 | validation loss: 0.0029415658168625413\n","Epoch: 99/99, Train acc: 99.12 | val acc: 97.37\n","------------------------------------------------------------------------------------------\n","Training Time(in minutes) = 0.01766095161437988\n"],"name":"stdout"}]}]}